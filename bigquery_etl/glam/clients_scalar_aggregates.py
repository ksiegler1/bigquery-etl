r"""Generate a query for incremental processing of scalar aggregates.

    python -m bigquery_etl.glam.scalar_aggregates_incremental --init \
        > sql/glam_etl/fenix_clients_scalar_aggregates_v1/init.sql

    python -m bigquery_etl.glam.scalar_aggregates_incremental \
        > sql/glam_etl/fenix_clients_scalar_aggregates_v1/query.sql
"""
from argparse import ArgumentParser
from typing import List

from jinja2 import Environment, PackageLoader

from bigquery_etl.format_sql.formatter import reformat


def render_main(
    header: str,
    user_data_type: str,
    user_data_attributes: List[str],
    attributes: List[str],
    extract_select_clause: str,
    join_filter: str,
    source_table: str,
    destination_table: str,
    **kwargs,
) -> str:
    """Render the main query."""
    env = Environment(loader=PackageLoader("bigquery_etl", "glam/templates"))
    main_sql = env.get_template("clients_scalar_aggregates_v1.sql")
    return reformat(
        main_sql.render(
            header=header,
            user_data_type=user_data_type,
            user_data_attributes=",".join(user_data_attributes),
            attributes=",".join(attributes),
            attributes_list=attributes,
            extract_select_clause=extract_select_clause,
            join_filter=join_filter,
            source_table=source_table,
            destination_table=destination_table,
        )
    )


def render_init(
    header,
    destination_table,
    attributes,
    attributes_type,
    user_data_type,
    partition_clause,
    **kwargs,
) -> str:
    """Render the table initialization DML for partitioning and clustering."""
    env = Environment(loader=PackageLoader("bigquery_etl", "glam/templates"))
    init_sql = env.get_template("clients_scalar_aggregates_v1.init.sql")
    return reformat(
        init_sql.render(
            header=header,
            destination_table=destination_table,
            attributes_type=",".join(
                f"{name} {dtype}" for name, dtype in zip(attributes, attributes_type)
            ),
            user_data_type=user_data_type,
            partition_clause=partition_clause,
        )
    )


def glean_variables():
    """Glean/Fenix specific variables."""
    return dict(
        # does not include "process" field
        user_data_type="""
            ARRAY<
                STRUCT<
                metric STRING,
                metric_type STRING,
                key STRING,
                agg_type STRING,
                value FLOAT64
                >
            >
        """,
        user_data_attributes=[
            "metric",
            "metric_type",
            "key",
            # [agg_type, value] are shared between telemetry and glean
        ],
        attributes=[
            "client_id",
            "ping_type",
            "os",
            "app_version",
            "app_build_id",
            "channel",
        ],
        attributes_type=["STRING", "STRING", "STRING", "INT64", "STRING", "STRING"],
        extract_select_clause="*",
        # NOTE: this will need to be refactored again when generalized to glean
        join_filter="""
            LEFT JOIN
                fenix_latest_versions_v1
            USING
                (channel)
            WHERE
                app_version >= (latest_version - 2)
        """,
        partition_clause="""
            PARTITION BY
                RANGE_BUCKET(app_version, GENERATE_ARRAY(0, 100, 1))
        """,
    )


def main():
    """Generate `glam.clients_scalar_aggregates_v1`."""
    parser = ArgumentParser(description=main.__doc__)
    parser.add_argument(
        "--source",
        default="glam.clients_daily_scalar_aggregates_v1",
        help="Source `clients_daily_scalar_aggregates` table",
    )
    parser.add_argument(
        "--destination",
        default="glam.clients_scalar_aggregates_v1",
        help="Destination for incremental `clients_scalar_aggregates` table",
    )
    parser.add_argument(
        "--init", action="store_true", help="generate init.sql instead of query.sql"
    )
    args = parser.parse_args()

    module_name = "bigquery_etl.glam.clients_scalar_aggregates"
    header = f"-- generated by: python3 -m {module_name}"
    if args.init:
        header += f" --init --source {args.source}"
    else:
        header += " " + " ".join(
            [f"--{k} {v}" for k, v in vars(args).items() if k != "init"]
        )

    render = render_init if args.init else render_main
    rendered = render(
        source_table=args.source,
        destination_table=args.destination,
        header=header,
        **glean_variables(),
    )
    print(rendered)


if __name__ == "__main__":
    main()
